{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from copy import deepcopy\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from setup_paths import paths\n",
    "from shutil import copyfile"
   ],
   "id": "c5724f82085cac68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rng = np.random.default_rng()",
   "id": "c628a6eb7e931715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save = \"cph_tud\"",
   "id": "6ca913cb3a9851a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "edge_dtypes = {\n",
    "    'NormalInfraType': int,\n",
    "    'UpgradedInfraType': int,\n",
    "    'IntersectionDelay': int,\n",
    "    'seg_id': int,\n",
    "    'cost': float,\n",
    "}\n",
    "g = ox.load_graphml(join(paths[\"input_folder\"], save, f\"{save}.graphml\"), edge_dtypes=edge_dtypes)\n",
    "for _, _, data in g.edges(data=True):\n",
    "    data[\"Active_Basis\"] = literal_eval(data[\"Active_Basis\"])\n",
    "    data[\"ex_inf\"] = literal_eval(data[\"ex_inf\"])\n",
    "    data[\"blocked\"] = literal_eval(data[\"blocked\"])\n",
    "    data[\"bike_highway\"] = literal_eval(data[\"bike_highway\"])\n",
    "cost = pd.read_csv(join(paths[\"data_dir\"], \"raw\", \"CPH\", \"SegmentCosts.csv\"))"
   ],
   "id": "be99ab2a11fcce18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(join(paths[\"input_folder\"], save, f\"{save}_demand.json\"), \"r\") as f:\n",
    "    demand = json.load(f)"
   ],
   "id": "72348d44d0a4aa51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "node_data = pd.read_csv(join(paths[\"data_dir\"], \"raw\", \"CPH\", \"NodesData.csv\"))\n",
    "zone_data = pd.read_csv(join(paths[\"data_dir\"], \"raw\", \"CPH\", \"CentroidsData.csv\"), sep=\",\", dtype={\"NodeId\": int, \"ZoneId\": int})\n",
    "node_data = pd.merge(node_data, zone_data, how=\"left\", on=\"NodeId\")\n",
    "node_data[\"ZoneId\"] = node_data[\"ZoneId\"].fillna(-1)\n",
    "node_data = node_data.astype({\"ZoneId\": \"int32\"})\n",
    "node_data[\"NodeId\"] += 1"
   ],
   "id": "509201cf171ecfa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "demand_df =  pd.read_csv(join(paths[\"data_dir\"], \"raw\", \"CPH\", \"ODData_Complete.csv\"), sep=\",\",\n",
    "                        dtype={\"FromZoneId\": int, \"ToZoneId\": int, \"TravelerType\": int, \"value\": float,\n",
    "                               \"gc_car\": float, \"gc_pt\": float, \"gc_walk\": float,\n",
    "                               \"gamma_car\": float, \"gamma_car_passenger\": float, \"gamma_pt\": float, \"gamma_walk\": float,\n",
    "                               \"p_other\": float}\n",
    "                        )"
   ],
   "id": "9e1b5591c0e7bb2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def demand_to_od_df(demand_dict, old_demand_csv, nodes):\n",
    "    new_demand_df = deepcopy(old_demand_csv)\n",
    "    \n",
    "    new_demand_df[\"FromNodeId\"] = new_demand_df.FromZoneId.map(nodes.set_index(\"ZoneId\")[\"NodeId\"].to_dict())\n",
    "    new_demand_df[\"ToNodeId\"] = new_demand_df.ToZoneId.map(nodes.set_index(\"ZoneId\")[\"NodeId\"].to_dict())\n",
    "    new_demand_df[\"FromTo\"] = list(zip(new_demand_df.FromNodeId, new_demand_df.ToNodeId))\n",
    "    new_demand_df[\"value\"] = [demand_dict[row[\"FromTo\"]][str(row[\"TravelerType\"])][\"number_of_users\"] for index, row in new_demand_df.iterrows()]\n",
    "    \n",
    "    new_demand_df.drop([\"FromNodeId\", \"ToNodeId\", \"FromTo\"], axis=1, inplace=True)\n",
    "    \n",
    "    return new_demand_df"
   ],
   "id": "b5e443da60f2d7a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def noisy_demand(demand_dict, delta): \n",
    "    noisy_demand_dict = {literal_eval(od): deepcopy(trips) for od, trips in demand_dict.items()}\n",
    "    \n",
    "    nodes = set()\n",
    "    for od in noisy_demand_dict.keys():\n",
    "        nodes.add(od[0])\n",
    "        nodes.add(od[1])\n",
    "    nodes_noisy = {node: rng.uniform(1 - delta, 1 + delta) for node in nodes}\n",
    "    \n",
    "    # traveler type: cyclist types with speed types increasing: 1-3 normal, 4-6 e-bike, 7-9 s-pedelec\n",
    "    for od, noisy_trips in noisy_demand_dict.items():\n",
    "        for c_type in noisy_trips.keys():\n",
    "            demand_old = demand_dict[f\"{od}\"][c_type][\"number_of_users\"]\n",
    "            noise_factor = (nodes_noisy[od[0]] + nodes_noisy[od[1]]) / 2\n",
    "            noisy_demand_dict[od][c_type][\"number_of_users\"] = demand_old * noise_factor\n",
    "    return noisy_demand_dict, nodes_noisy"
   ],
   "id": "6c1d1463c1dcd0f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def noisy_speeds(speeds_array, delta):\n",
    "    high = 1 + delta\n",
    "    low = 1 - delta\n",
    "    \n",
    "    speeds = np.array([\n",
    "        [[13.6, 15.1, 16.6], [16.3, 17.8, 19.3], [19.1, 20.8, 22.5]],\n",
    "        [[15.6, 17.1, 18.6], [18.3, 19.8, 21.3], [21.1, 22.8, 24.5]],\n",
    "        [[22.6, 24.1, 25.6], [25.3, 26.8, 28.3], [27.3, 29.8, 31.5]],\n",
    "    ])\n",
    "    noisy_speeds_array = np.zeros((3, 3, 3))\n",
    "    noisy_speeds_dict = {\"super_speeds\": np.zeros(9), \"bp_speeds\": np.zeros(9), \"street_speeds\": np.zeros(9)}\n",
    "    \n",
    "    bike_types = [\"bike\", \"e-bike\", \"s-pedelec\"]\n",
    "    speed_types = [\"slow\", \"medium\", \"fast\"]\n",
    "    \n",
    "    for i in range(9):\n",
    "        bike_type = i // 3\n",
    "        speed_type = i % 3\n",
    "        cyclist_type = f\"{bike_types[bike_type]} {speed_types[speed_type]}\"\n",
    "        \n",
    "        new_street_speed = speeds[bike_type][speed_type][0] * rng.uniform(low, high)\n",
    "        new_bp_speed = speeds[bike_type][speed_type][1] * rng.uniform(low, high)\n",
    "        new_super_speed = speeds[bike_type][speed_type][2] * rng.uniform(low, high)\n",
    "        \n",
    "        while new_super_speed < new_bp_speed or new_bp_speed < new_street_speed or new_super_speed < new_street_speed \\\n",
    "                or new_super_speed < noisy_speeds_array[max(bike_type-1,0)][speed_type][2] or new_bp_speed < noisy_speeds_array[max(bike_type-1,0)][speed_type][1] or new_street_speed < noisy_speeds_array[max(bike_type-1,0)][speed_type][0] \\\n",
    "                or new_super_speed < noisy_speeds_array[bike_type][max(speed_type-1,0)][2] or new_bp_speed < noisy_speeds_array[bike_type][max(speed_type-1,0)][1] or new_street_speed < noisy_speeds_array[bike_type][max(speed_type-1,0)][0]:\n",
    "            new_super_speed = speeds[bike_type][speed_type][0] * rng.uniform(low, high)\n",
    "            new_bp_speed = speeds[bike_type][speed_type][1] * rng.uniform(low, high)\n",
    "            new_street_speed = speeds[bike_type][speed_type][2] * rng.uniform(low, high)\n",
    "        \n",
    "        noisy_speeds_array[bike_type][speed_type][0] = new_street_speed\n",
    "        print(f\"{cyclist_type} on streets: {new_street_speed:2.3f}\")\n",
    "        noisy_speeds_array[bike_type][speed_type][1] = new_bp_speed\n",
    "        print(f\"{cyclist_type} on bike paths: {new_bp_speed:2.3f}\")\n",
    "        noisy_speeds_array[bike_type][speed_type][2] = new_super_speed\n",
    "        print(f\"{cyclist_type} on highways: {new_super_speed:2.3f}\")\n",
    "    \n",
    "        noisy_speeds_dict[\"street_speeds\"][i] = new_street_speed\n",
    "        noisy_speeds_dict[\"bp_speeds\"][i] = new_bp_speed\n",
    "        noisy_speeds_dict[\"super_speeds\"][i] = new_super_speed\n",
    "    \n",
    "    noisy_speeds_dict = {k: v.tolist() for k, v in noisy_speeds_dict.items()}\n",
    "    return noisy_speeds_dict"
   ],
   "id": "f165d901992022b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def noisy_costs(g, cost_df, delta):  \n",
    "    noisy_cost_df = deepcopy(cost_df)\n",
    "    noisy_g = deepcopy(g)\n",
    "    \n",
    "    noisy_cost_df[\"ConstructionCosts\"] = noisy_cost_df[\"ConstructionCosts\"] * rng.uniform(1 - delta, 1 + delta, len(noisy_cost_df[\"ConstructionCosts\"]))\n",
    "    noisy_cost_df[\"MaintenanceCosts\"] = noisy_cost_df[\"MaintenanceCosts\"] * rng.uniform(1 - delta, 1 + delta, len(noisy_cost_df[\"MaintenanceCosts\"]))\n",
    "    \n",
    "    for _, _, data in noisy_g.edges(data=True):\n",
    "        if data[\"seg_id\"] != -1:\n",
    "            data[\"cost\"] = noisy_cost_df.loc[noisy_cost_df[\"SegmentId\"]==data[\"seg_id\"], \"ConstructionCosts\"].values[0]\n",
    "            \n",
    "    return noisy_g, noisy_cost_df"
   ],
   "id": "ceaa5836c028d130",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def noisy_utilities(vod, vot, delta):  \n",
    "    vod_noisy = {k: v * rng.uniform(1 - delta, 1 + delta) for k, v in vod.items()}\n",
    "    vot_noisy = vot * rng.uniform(1 - delta, 1 + delta)\n",
    "    \n",
    "    return vod_noisy, vot_noisy"
   ],
   "id": "9eb06bfd9e2016cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def gen_noisy_costs(d, clean_costs, noisy_cost_save):\n",
    "    noisy_cost_folder = join(paths[\"input_folder\"], noisy_cost_save)\n",
    "    Path(noisy_cost_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    g_noisy, cost_noisy = noisy_costs(g, clean_costs, d)\n",
    "    ox.save_graphml(g_noisy, join(noisy_cost_folder, f\"{noisy_cost_save}.graphml\"))\n",
    "    cost_noisy.to_csv(join(paths[\"data_dir\"], \"raw\", \"CPH\", f\"SegmentCosts_noisy_{noisy_cost_save}.csv\"))\n",
    "    \n",
    "    copyfile(join(paths[\"input_folder\"], save, f\"{save}_demand.json\"), join(noisy_cost_folder, f\"{noisy_cost_save}_demand.json\"))\n",
    "    copyfile(join(paths[\"input_folder\"], save, f\"{save}_speeds.json\"), join(noisy_cost_folder, f\"{noisy_cost_save}_speeds.json\"))"
   ],
   "id": "392d2b257b043df9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def gen_noisy_demand(d, clean_demand, noisy_demand_save, nodes):\n",
    "    noisy_demand_folder = join(paths[\"input_folder\"], noisy_demand_save)\n",
    "    Path(noisy_demand_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    demand_noisy, nodes_noise = noisy_demand(clean_demand, d)\n",
    "    demand_df_noisy = demand_to_od_df(demand_noisy, demand_df, nodes)\n",
    "    with open(join(noisy_demand_folder, f\"{noisy_demand_save}_demand.json\"), \"w\") as fp:\n",
    "        json.dump({str(k): {int(v_k): v_v for v_k, v_v in v.items()} for k, v in demand_noisy.items()}, fp)\n",
    "    with open(join(noisy_demand_folder, f\"{noisy_demand_save}_node_noise.json\"), \"w\") as fp:\n",
    "        json.dump(nodes_noise, fp)\n",
    "    demand_df_noisy.to_csv(join(paths[\"data_dir\"], \"raw\", \"CPH\", f\"ODData_Complete_noisy_{noisy_demand_save}.csv\"), index=False)\n",
    "    \n",
    "    copyfile(join(paths[\"input_folder\"], save, f\"{save}.graphml\"), join(noisy_demand_folder, f\"{noisy_demand_save}.graphml\"))\n",
    "    copyfile(join(paths[\"input_folder\"], save, f\"{save}_speeds.json\"), join(noisy_demand_folder, f\"{noisy_demand_save}_speeds.json\"))"
   ],
   "id": "bc7410702a78845a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def gen_noisy_speeds(d, noisy_speeds_save):\n",
    "    noisy_speeds_folder = join(paths[\"input_folder\"], noisy_speeds_save)\n",
    "    Path(noisy_speeds_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    speeds_noisy_dict = noisy_speeds({}, d)\n",
    "    with open(join(noisy_speeds_folder, f\"{noisy_speeds_save}_speeds.json\"), \"w\") as fp:\n",
    "        json.dump(speeds_noisy_dict, fp)\n",
    "        \n",
    "    copyfile(join(paths[\"input_folder\"], save, f\"{save}.graphml\"), join(noisy_speeds_folder, f\"{noisy_speeds_save}.graphml\"))\n",
    "    copyfile(join(paths[\"input_folder\"], save, f\"{save}_demand.json\"), join(noisy_speeds_folder, f\"{noisy_speeds_save}_demand.json\"))"
   ],
   "id": "ccb032ed95c783af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "delta_noise = 0.20\n",
    "for i in range(1, 11):\n",
    "    gen_noisy_speeds(delta_noise, f\"{save}_noisy_speeds_{i}\")\n",
    "    gen_noisy_costs(delta_noise, cost, f\"{save}_noisy_costs_{i}\")\n",
    "    gen_noisy_demand(delta_noise, demand, f\"{save}_noisy_demand_{i}\", node_data)"
   ],
   "id": "5fc441bdb989551e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
